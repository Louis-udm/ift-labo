{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "D\u00e9monstration 4: K-PPV, ensembles d'entra\u00eenement et de test, surface de d\u00e9cision. 26/09"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La semaine derni\u00e8re vous avez implant\u00e9 un 1-Plus-Proche-Voisin (1-PPV). Cette semaine vous implanterez un K-PPV. Par contre, cette semaine nous ferons aussi appel \u00e0 la notion d'ensembles d'entrainement et de test, ainsi qu'\u00e0 la notion de surface de d\u00e9cision. \n",
      "\n",
      "\n",
      "- Votre premi\u00e8re \u00e9tape est de vous rem\u00e9morer le fonctionnement du K-PPV.\n",
      "- Nous fournissons le cadre g\u00e9n\u00e9ral o\u00f9 il vous faudra ins\u00e9rer le code de k-ppv. On y retrouve notamment des fonctions pour rendre certaines t\u00e2ches (comme l'affichage des r\u00e9sultats) plus faciles. Cela vous permettra de vous concentrer sur la partie algorithmique de cette d\u00e9monstration. T\u00e9l\u00e9chargez et le notebook fourni.\n",
      "- Ex\u00e9cutez toutes les cellures de code en cliquant dans le menu Cell/Run all: Vous observez \u00e0 la derni\u00e8re cellule le fonctionnement d'un classifieur qui fait une pr\u00e9diction constante (c'est-\u00e0-dire qu'il pr\u00e9dit, pour chaque exemple, l'\u00e9tiquette 1 (bleu)).\n",
      "Familiarisez-vous avec le code des cinq sections suivantes:\n",
      "    - **Fonctions utilitaires:** d\u00e9finit des fonctions utiles (visualisation, \u00e9valuation)\n",
      "    - **Classe k-ppv:** c'est ici que vous devez implanter le classifieur.\n",
      "    - **Chargement et division des donn\u00e9es:** charge un jeu de donn\u00e9es et le divise en deux parties (train, test)\n",
      "    - **Initialisation et entra\u00eenement du classifieur:** entra\u00eene un mod\u00e8le k-PPV sur les donn\u00e9es d'entra\u00eenement et obtient les pr\u00e9dictions des \u00e9tiquettes pour les donn\u00e9es de test\n",
      "    - **Matrice de confusion et surface de d\u00e9cision:** Affiche la matrice de confusion et visualise la surface de d\u00e9cision\n",
      "\n",
      "**Votre objectif pour la s\u00e9ance** est de comprendre le fonctionnement g\u00e9n\u00e9ral du code fourni puis de compl\u00e9ter la fonctionkppv.compute_predictions().\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classes en python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pour cette d\u00e9mo, nous impl\u00e9menterons k-ppv \u00e0 l'int\u00e9rieure d'une **classe**. Vous pouvez lire ce [tutoriel](http://docs.python.org/2/tutorial/classes.html) si vous n'\u00eates pas \u00e0 l'aise avec les classes en python. La classe `kppv` est d\u00e9j\u00e0 partiellement impl\u00e9ment\u00e9 \u00e0 la section **Classe k-ppv**, il ne vous reste qu'\u00e0 compl\u00e9ter la m\u00e9thode `compute_predictions`"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fonctions utilitaires"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vous n'avez rien \u00e0 impl\u00e9menter ici. Lisez simplement le code et familiarisez vous avez. Il sera possible de tester les fonctions `teste` et tout particuli\u00e8rement `gridplot` \u00e0 la fin du notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import random\n",
      "import pylab\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cette fonction calcule la distance Minkowski entre un vecteur x et une matrice Y. \u00c7a vous rappelle quelque chose?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minkowski_mat(x,Y,p=2):\n",
      "    return (np.sum((np.abs(x-Y))**p,axis=1))**(1.0/p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La fonction `conf_matrix` prend en entr\u00e9e:\n",
      "\n",
      " - `etiquettesTest` - les \u00e9tiquettes de test\n",
      " - `etiquettesPred` - les \u00e9tiquettes pr\u00e9dites\n",
      "et retourne une table pr\u00e9sentant les r\u00e9sultats\n",
      "\n",
      "Voir la d\u00e9finition d'une [matrice de confusion](http://fr.wikipedia.org/wiki/Matrice_de_confusion)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conf_matrix(etiquettesTest, etiquettesPred):\n",
      "\n",
      "\tn_classes = max(etiquettesTest)\n",
      "\tmatrix = np.zeros((n_classes,n_classes))\n",
      "\n",
      "\tfor (test,pred) in zip(etiquettesTest, etiquettesPred):\n",
      "\t\tmatrix[test-1,pred-1] += 1\n",
      "\n",
      "\treturn matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La fonction `gridplot` prend en entr\u00e9e:\n",
      "\n",
      " - `classifieur` - un classifieur tel que `kppv`\n",
      " - `train` - un ensemble d'entra\u00eenement\n",
      " - `test` - un ensemble de test\n",
      " - `n_points` - la taille de la grille pour afficher la surface de d\u00e9cision (x,x)\n",
      "\n",
      "D\u00e9pendamment de la puissance de calcul de votre ordinateur, le calcul des pr\u00e9dictions sur la grille peut \u00eatre lent. Il est pr\u00e9f\u00e9rable de faire vos premiers tests avec une grille moins fine, disons de 25 par 25. Vous pourrez ensuite augmenter la valeur \u00e0 50 ou m\u00eame 100 pour obtenir de plus beaux graphiques."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fonction plot\n",
      "def gridplot(classifieur,train,test,n_points=50):\n",
      "\n",
      "    train_test = np.vstack((train,test))\n",
      "    (min_x1,max_x1) = (min(train_test[:,0]),max(train_test[:,0]))\n",
      "    (min_x2,max_x2) = (min(train_test[:,1]),max(train_test[:,1]))\n",
      "\n",
      "    xgrid = np.linspace(min_x1,max_x1,num=n_points)\n",
      "    ygrid = np.linspace(min_x2,max_x2,num=n_points)\n",
      "\n",
      "\t# calcule le produit cartesien entre deux listes\n",
      "    # et met les resultats dans un array\n",
      "    thegrid = np.array(combine(xgrid,ygrid))\n",
      "\n",
      "    les_comptes = classifieur.compute_predictions(thegrid)\n",
      "    classesPred = np.argmax(les_comptes,axis=1)+1\n",
      "\n",
      "    # La grille\n",
      "    # Pour que la grille soit plus jolie\n",
      "    #props = dict( alpha=0.3, edgecolors='none' )\n",
      "    #pylab.scatter(thegrid[:,0],thegrid[:,1],c = classesPred, s=50, edgecolors='none', alpha=0.1)\n",
      "    pylab.pcolormesh(xgrid, ygrid, classesPred.reshape((n_points, n_points)).T, alpha=.3)\n",
      "\t# Les points d'entrainment\n",
      "    pylab.scatter(train[:,0], train[:,1], c = train[:,-1], marker = 'v', s=150)\n",
      "    # Les points de test\n",
      "    pylab.scatter(test[:,0], test[:,1], c = test[:,-1], marker = 's', s=150)\n",
      "\n",
      "    ## Un petit hack, parce que la fonctionalite manque a pylab...\n",
      "    h1, = pylab.plot([min_x1], [min_x2], marker='o', c = 'w',ms=5) \n",
      "    h2, = pylab.plot([min_x1], [min_x2], marker='v', c = 'w',ms=5) \n",
      "    h3, = pylab.plot([min_x1], [min_x2], marker='s', c = 'w',ms=5) \n",
      "    handles = [h1,h2,h3]\n",
      "    ## fin du hack\n",
      "\n",
      "    labels = ['grille','train','test']\n",
      "    pylab.legend(handles,labels)\n",
      "\n",
      "    pylab.axis('equal')\n",
      "    pylab.show()\n",
      "    \n",
      "## http://code.activestate.com/recipes/302478/\n",
      "def combine(*seqin):\n",
      "    '''returns a list of all combinations of argument sequences.\n",
      "for example: combine((1,2),(3,4)) returns\n",
      "[[1, 3], [1, 4], [2, 3], [2, 4]]'''\n",
      "    def rloop(seqin,listout,comb):\n",
      "        '''recursive looping function'''\n",
      "        if seqin:                       # any more sequences to process?\n",
      "            for item in seqin[0]:\n",
      "                newcomb=comb+[item]     # add next item to current comb\n",
      "                # call rloop w/ rem seqs, newcomb\n",
      "                rloop(seqin[1:],listout,newcomb)\n",
      "        else:                           # processing last sequence\n",
      "            listout.append(comb)        # comb finished, add to list\n",
      "    listout=[]                      # listout initialization\n",
      "    rloop(seqin,listout,[])         # start recursive process\n",
      "    return listout\n",
      "\n",
      "matplotlib.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'1.5.3'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classe k-ppv"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La classe `kppv` prend en param\u00e8tre:\n",
      "\n",
      " - `n_classes` - le nombre de classe du probl\u00e8me\n",
      " - `dist_func` - une fonction pour calculer la distance des points\n",
      " - `n_voisins` - le nombre de voisin \u00e0 visiter \n",
      "\n",
      "La m\u00e9thode `train` n'est en fait que le stockage de l'ensemble d'entra\u00eenement. Tout le travail du mod\u00e8le $k$-ppv s'\u00e9ffectue lors de la pr\u00e9diction. \n",
      "\n",
      "La m\u00e9thode `compute_predictions` prend en entr\u00e9 une matrice de donn\u00e9es de test (sans \u00e9tiquettes) et retourne une matrice des comptes pour chaque exemple de test. Cette matrice est donc de dimensions (n_exemple,n_classes).\n",
      "\n",
      "Vous devrez pour chaque point de l'ensemble de test :\n",
      "\n",
      " - **calculer les distances** \u00e0 tous les points de l'ensemble d'entra\u00eenement (en utilisant dist_func)\n",
      " - parcourir les distances pour **trouver les $k$ voisins** du point de test courant\n",
      " - **d\u00e9nombrer les voisins** correspondant \u00e0 chaque classe et les sauvegarder dans les_comptes\n",
      "\n",
      "**Note :** La sortie de la m\u00e9thode `kppv.compute_predictions()` doit \u00eatre assez g\u00e9n\u00e9rale pour qu'on puisse l'utiliser dans plusieurs contextes. C'est pour cela qu'on vous demande que la fonction retourne une matrice qui contient des comptes pour chaque exemple de test et non pas les classes pr\u00e9dites pour chaque exemple de test."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class kppv:\n",
      "    def __init__(self,n_classes, dist_func=minkowski_mat, n_voisins=1):\n",
      "        self.n_classes = n_classes\n",
      "        self.dist_func = dist_func\n",
      "        self.n_voisins = n_voisins\n",
      "\n",
      "    # La fonction d'entrainement d'un k-PPV est juste le stockage de l'ensemble d'entrainement\n",
      "    def train(self, train_inputs, train_labels):\n",
      "        self.train_inputs = train_inputs\n",
      "        self.train_labels = train_labels\n",
      "\n",
      "    ###\n",
      "    # La fonction de pr\u00e9diction prend en entr\u00e9e:\n",
      "    #   test_data - les donn\u00e9es de test (sans l'\u00e9tiquette)\n",
      "    # et retourne une matrice des comptes pour chaque exemple de test. \n",
      "    # Chaque rang\u00e9e de cette matrice contient, pour chaque classe, le nombre \n",
      "    # de voisins appartenant \u00e0 cette classe. \n",
      "    ###\n",
      "    def compute_predictions(self, test_data):\n",
      "        # Initialisation de la matrice \u00e0 retourner\n",
      "        num_test = test_data.shape[0]\n",
      "        les_comptes = np.ones((num_test,self.n_classes))\n",
      "\n",
      "        # Pour chaque point de test\n",
      "        for (i,ex) in enumerate(test_data):\n",
      "            # i est l'indice de la rang\u00e9e\n",
      "            # ex est la i'eme rang\u00e9e\n",
      "\n",
      "            # trouve les distances \u00e0 tous les pointsd'entrainement\n",
      "            distances = self.dist_func(ex,self.train_inputs)\n",
      "            # garde l'index des k plus proches voisins\n",
      "            ind_voisins = np.argsort(distances)[:self.n_voisins]\n",
      "            # liste des k plus proches voisins\n",
      "            cl_voisins = list(self.train_labels[ind_voisins]-1)\n",
      "            \n",
      "            # D\u00e9nombre les voisins correspondant \u00e0 chaque classe les mets dans les_comptes[i,:]\n",
      "            # on prend le min de k et data.shape[0] pour permettre un k plus grand que le nombre d'exemples\n",
      "            for j in range(min(self.n_voisins,self.train_inputs.shape[0])):\n",
      "                cl_voisins[j]\n",
      "                les_comptes[i]\n",
      "                les_comptes[i,cl_voisins[j]] += 1\n",
      "\n",
      "        return les_comptes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Chargement et division des donn\u00e9es"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "L'ensemble de donn\u00e9e `iris` est divis\u00e9 en deux parties, une pour l'entra\u00eenement et l'autre pour \u00e9ffectuer des tests. Il est important de m\u00e9langer al\u00e9atoirement l'ensemble de donn\u00e9es avant d'\u00e9ffectuer la division. Pouvez vous dire pourquoi? \n",
      "\n",
      "Seulement deux colonnes des donn\u00e9es sont utilis\u00e9es afin de pouvoir les visualiser en deux dimensions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# charger iris\n",
      "iris = np.loadtxt('iris.txt')\n",
      "data = iris\n",
      "\n",
      "# Nombre de classes\n",
      "n_classes = 3\n",
      "\n",
      "# Nombre de points d'entrainement\n",
      "n_train = 100\n",
      "\n",
      "# Les colonnes (traits/caracteristiques) sur lesqueles on va entrainer notre modele\n",
      "# Pour que gridplot fonctionne, len(train_cols) devrait etre 2\n",
      "train_cols = [0,1]\n",
      "# L'indice de la colonne contenant les etiquettes\n",
      "target_ind = [data.shape[1] - 1]\n",
      "\n",
      "# Commenter pour avoir des resultats non-deterministes \n",
      "random.seed(3395)\n",
      "# Determiner au hasard des indices pour les exemples d'entrainement et de test\n",
      "inds = range(data.shape[0])\n",
      "random.shuffle(inds)\n",
      "train_inds = inds[:n_train]\n",
      "test_inds = inds[n_train:]\n",
      "\n",
      "# Separer les donnees dans les deux ensembles\n",
      "train_set = data[train_inds,:]\n",
      "train_set = train_set[:,train_cols + target_ind]\n",
      "test_set = data[test_inds,:]\n",
      "test_set = test_set[:,train_cols + target_ind]\n",
      "\n",
      "# Separarer l'ensemble de train et test dans les entrees et les etiquettes\n",
      "train_inputs = train_set[:, :-1]\n",
      "train_labels = train_set[:, -1].astype('int32')\n",
      "test_inputs = test_set[:,:-1]\n",
      "test_labels = test_set[:,-1].astype('int32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initialisation et entra\u00eenement du classifieur"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On prends ici la argmax des pr\u00e9dictions pour avoir la classe majoritaire pour chaque exemple du test. \n",
      "\n",
      "N'oubliez pas de r\u00e9ex\u00e9cuter cette cellule si vous avez modifi\u00e9 votre mod\u00e8le et voulez afficher la surface de d\u00e9cision \u00e0 la section suivante. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Nombre de voisins (k) dans k-PPV\n",
      "k = 10\n",
      "print \"On va entrainer un \",k, \"-PPV sur \", n_train, \" exemples d'entrainement\"\n",
      "\n",
      "# Cr\u00e9er le classifieur\n",
      "model = kppv(n_classes,dist_func = minkowski_mat, n_voisins = k)\n",
      "# L'entrainer\n",
      "model.train(train_inputs, train_labels)\n",
      "# Obtenir ses predictions\n",
      "t1 = time.clock()\n",
      "les_comptes = model.compute_predictions(test_inputs)\n",
      "t2 = time.clock()\n",
      "print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', test_inputs.shape[0],' points de test'\n",
      "\n",
      "# Vote majoritaire (+1 puisque nos classes sont de 1 a n)\n",
      "classes_pred = np.argmax(les_comptes,axis=1)+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matrice de confusion et surface de d\u00e9cision"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On imprime ici la matrice de confusion, tr\u00e8s utile pour comprendre quelles classes sont moins bien pr\u00e9dites par notre classifieur. On cr\u00e9e aussi un graphique qui affiche les points d'entra\u00eenement ainsi que ceux de test et la surface de d\u00e9cision de notre mod\u00e8le. \n",
      "\n",
      "Avant de passer \u00e0 la section suivante, assurez-vous que votre impl\u00e9mentation de $k$-ppv fonctionne bien en ex\u00e9cutant ce code. N'h\u00e9sitez surtout pas \u00e0 poser des questions si vous avez de la difficult\u00e9 \u00e0 interpr\u00e9ter la matrice de confusion et le graphique."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Faire les tests\n",
      "# Matrice de confusion \n",
      "confmat = conf_matrix(test_labels, classes_pred)\n",
      "print 'La matrice de confusion est:'\n",
      "print confmat\n",
      "\n",
      "# Erreur de test\n",
      "sum_preds = np.sum(confmat)\n",
      "sum_correct = np.sum(np.diag(confmat))\n",
      "print \"L'erreur de test est de \", 100*(1.0 - (float(sum_correct) / sum_preds)),\"%\"\n",
      "\n",
      "# Taille de la grille = grid_size x grid_size\n",
      "grid_size = 200\n",
      "\n",
      "if len(train_cols) == 2:\n",
      "    # Surface de decision\n",
      "    t1 = time.clock()\n",
      "    gridplot(model,train_set,test_set,n_points = grid_size)\n",
      "    t2 = time.clock()\n",
      "    print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', grid_size * grid_size, ' points de la grille'\n",
      "    filename = 'grille_' + '_k=' + str(k) + '_c1=' + str(train_cols[0]) + '_c2=' + str(train_cols[1])+'.png'\n",
      "    print 'On va sauvegarder la figure dans ', filename\n",
      "    pylab.savefig(filename,format='png')\n",
      "else:\n",
      "    print 'Trop de dimensions (', len(train_cols),') pour pouvoir afficher la surface de decision'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exp\u00e9rimentations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maintenant que tous fonctionne, il est temps de faire des exp\u00e9rimentations pour mieux comprendre l'importance de diff\u00e9rents facteurs. Travaillez directement sur le code pr\u00e9c\u00e9dent pour effectuer ces tests. \n",
      "\n",
      "- Variez les tailles de `train_set` et `test_set` et observez l'impact sur l'erreur de test et la surface de d\u00e9cision\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> \u00c0 vous d'exp\u00e9rimenter avec le code pr\u00e9c\u00e9dent.\n",
      "\n",
      "> Vous devriez voir que l'erreur sur l'ensemble de test augmente \u00e0 mesure que l'ensemble d'entra\u00eenement est plus petite. On va toujours essayer\n",
      "> d'avoir un ensemble d'entra\u00eenement le plus grand possible afin de s'approcher au maximum de la *distribution naturelle* des exemples. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Essayez $k=1,2,\\dots,10$. \n",
      "  - Est-ce que l'erreur de test change? \n",
      "  - Est-ce qu'il existe un $k$ optimal? \n",
      "  - Est-ce qu'en regardant seulement la surface de d\u00e9cision vous \u00eates en mesure de dire quel $k$ est optimal?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Encore une fois, \u00e0 vous d'exp\u00e9rimenter avec le code pr\u00e9c\u00e9dent.\n",
      "\n",
      "> L'erreur de test devrait changer d'un $k$ \u00e0 l'autre. Avec le m\u00eame *seed* que dans ce code, vous devriez trouver $k=7$ comme optimal. \n",
      "> Remarquez que la fluctuation de l'erreur de test est en dent de scie et de quelque % seulement pour des $k$ allant de 1 \u00e0 10 dans ce cas ci.\n",
      "> Il est difficile de voir sur le graphique de la surface de d\u00e9cision\n",
      "> quel $k$ est optimal. Cependant, la r\u00e9duction de la capacit\u00e9 du mod\u00e8le lorsque $k$ augmente est visible avec les fronti\u00e8res de \n",
      "> la surface de d\u00e9cision qui deviennent plus lisse. C'est-\u00e0-dire que plus $k$ est grand, moins la puissance de repr\u00e9sentation du mod\u00e8le est forte. Le cas extr\u00e8me de $k=1$ est un exemple frappant o\u00f9 le mod\u00e8le est capable d'apprendre par coeur tout les ensembles d'entra\u00eenement. Une grande capacit\u00e9 est importante pour pouvoir repr\u00e9senter des donn\u00e9es complexes, mais elle vient avec le danger de pouvoir sur-apprendre l'ensemble d'entra\u00eenement et mal g\u00e9n\u00e9raliser sur l'ensemble de test comme dans le cas $k=1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Divisez l'ensemble d'entrainement en 3 parties: `train_set`, `valid_set` et `test_set` (de taille 100, 25 et 25, par exemple). Entrainez $k$-ppv sur `train_set`, choisissez la valeur optimale de `k` en testant sur `valid_set` et obtenez un estim\u00e9 de l'erreur de g\u00e9n\u00e9ralisation en testant sur `test_set`. Cette fois-ci, utilisez tous les (quatre) traits/caract\u00e9ristiques/features. D'apr\u00e8s-vous, \u00e0 quoi sert l'ensemble de validation?\n",
      "  - Est-ce qu'il y a un \u00e9cart entre l'erreur de validation et l'erreur de test pour le $k$ optimal trouv\u00e9 avec l'ensemble de validation? Est-ce qu'il devrait y en avoir? (la r\u00e9ponse se trouve dans la question)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def experience(n_train=100,n_valid=25,train_cols=[0,1],ks=[1],seed=3395):\n",
      "\n",
      "    # L'indice de la colonne contenant les etiquettes\n",
      "    target_ind = [data.shape[1] - 1]\n",
      "\n",
      "    # Commenter pour avoir des resultats non-deterministes \n",
      "    if seed:\n",
      "        random.seed(seed)\n",
      "    # Determiner au hasard des indices pour les exemples d'entrainement et de test\n",
      "    inds = range(data.shape[0])\n",
      "    random.shuffle(inds)\n",
      "    assert n_train+n_valid < data.shape, \"il ne reste aucun exemple pour l'ensemble de test\"\n",
      "    train_inds = inds[:n_train]\n",
      "    valid_inds = inds[n_train:n_train+n_valid]\n",
      "    test_inds = inds[n_train+n_valid:]\n",
      "\n",
      "    # Separer les donnees dans les deux ensembles\n",
      "    train_set = data[train_inds,:]\n",
      "    train_set = train_set[:,train_cols + target_ind]\n",
      "    valid_set = data[valid_inds,:]\n",
      "    valid_set = valid_set[:,train_cols+target_ind]\n",
      "    test_set = data[test_inds,:]\n",
      "    test_set = test_set[:,train_cols + target_ind]\n",
      "    \n",
      "    # Separarer l'ensemble de test dans les entrees et les etiquettes\n",
      "    train_inputs = train_set[:, :-1]\n",
      "    train_labels = train_set[:, -1].astype('int32')\n",
      "    valid_inputs = valid_set[:,:-1]\n",
      "    valid_labels = valid_set[:,-1].astype('int32')\n",
      "    test_inputs = test_set[:,:-1]\n",
      "    test_labels = test_set[:,-1].astype('int32')\n",
      "    \n",
      "    best_result = float('inf')\n",
      "    best_k = 0\n",
      "    best_model = None\n",
      "    for k in ks:\n",
      "        # Cr\u00e9er le classifieur\n",
      "        model = kppv(n_classes,dist_func = minkowski_mat, n_voisins = k)\n",
      "        # L'entrainer\n",
      "        model.train(train_inputs, train_labels)\n",
      "        # Obtenir ses predictions\n",
      "        les_comptes = model.compute_predictions(valid_inputs)\n",
      "\n",
      "        # Vote majoritaire (+1 puisque nos classes sont de 1 a n)\n",
      "        classes_pred = np.argmax(les_comptes,axis=1)+1\n",
      "        \n",
      "        result = (1.0-(valid_labels==classes_pred).mean())\n",
      "        \n",
      "        if result < best_result:\n",
      "            best_model = model\n",
      "            best_k = k\n",
      "            best_result = result\n",
      "    \n",
      "    return train_set, valid_set, test_set, best_model, best_k\n",
      "    \n",
      "def graphiques(train_set, valid_set, test_set, model):\n",
      "\n",
      "    valid_inputs = valid_set[:,:-1]\n",
      "    test_inputs = test_set[:,:-1]\n",
      "    valid_labels = valid_set[:,-1].astype('int32')\n",
      "    test_labels = test_set[:,-1].astype('int32')\n",
      "    \n",
      "    les_comptes = model.compute_predictions(valid_inputs)\n",
      "    valid_pred = np.argmax(les_comptes,axis=1)+1\n",
      "    les_comptes = model.compute_predictions(test_inputs)\n",
      "    test_pred = np.argmax(les_comptes,axis=1)+1    \n",
      "    \n",
      "    # Matrice de confusion\n",
      "    confmat = conf_matrix(valid_labels, valid_pred)\n",
      "    print \"La matrice de confusion pour l'ensemble de validation est:\"\n",
      "    print confmat\n",
      "    \n",
      "    # Matrice de confusion\n",
      "    confmat = conf_matrix(test_labels, test_pred)\n",
      "    print \"La matrice de confusion pour l'ensemble de test est:\"\n",
      "    print confmat\n",
      "\n",
      "    # Erreur de validation\n",
      "    print \"L'erreur de validation est de \", 100.*(1.0 - (valid_labels==valid_pred)).mean(),\"%\"\n",
      "    \n",
      "    # Erreur de test\n",
      "    print \"L'erreur de test est de \", 100.*(1.0 - (test_labels==test_pred)).mean(),\"%\"\n",
      "\n",
      "    # Taille de la grille = grid_size x grid_size\n",
      "    grid_size = 200\n",
      "\n",
      "    if len(train_cols) == 2:\n",
      "        # Surface de decision\n",
      "        gridplot(model,train_set,test_set,n_points = grid_size)\n",
      "        print 'On va sauvegarder la figure dans ', filename\n",
      "        pylab.savefig(filename,format='png')\n",
      "    else:\n",
      "        print 'Trop de dimensions (', len(train_cols),') pour pouvoir afficher la surface de decision'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, valid_set, test_set, best_model, best_k = experience(n_train=100,n_valid=25,train_cols=[0,1],ks=xrange(1,100))\n",
      "print \"le meilleur k est \",best_k\n",
      "graphiques(train_set, valid_set, test_set, best_model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- D\u00e9commentez la ligne `random.seed(3395)` et roulez votre code plusieurs fois pour obtenir des statistiques sur les erreurs de validation et de test. Vous pouvez \u00e9crire une boucle `for` qui ex\u00e9cute le m\u00eame code plusieurs fois; 10 fois devrait suffire. Calculez l'\u00e9cart-type et la moyenne de chaque erreur."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10\n",
      "results = np.zeros(N)\n",
      "# on test N fois le mod\u00e8le sur les m\u00eame ensemble\n",
      "for i in range(N):\n",
      "    train_set, valid_set, test_set, best_model, best_k = experience(n_train=100,n_valid=25,train_cols=[0,1],ks=[7],seed=False)\n",
      "    \n",
      "    test_inputs = test_set[:,:-1]\n",
      "    test_labels = test_set[:,-1].astype('int32')\n",
      "    \n",
      "    les_comptes = model.compute_predictions(test_inputs)\n",
      "    test_pred = np.argmax(les_comptes,axis=1)+1    \n",
      "    \n",
      "    # Erreur de test\n",
      "    results[i] = 100.*(1.0 - (test_labels==test_pred)).mean()\n",
      "\n",
      "# l'\u00e9cart-type est consid\u00e9rable \u00e9tant donn\u00e9 la moyenne d'erreur\n",
      "# on voit que le seed est important pour la reproductibilit\u00e9 des exp\u00e9riences\n",
      "print results\n",
      "print \"Moyenne\", results.mean()\n",
      "print \"\u00c9cart-type\", results.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
