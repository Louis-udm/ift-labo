{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démonstration 4: K-PPV, ensembles d'entraînement et de test, surface de décision. 26/09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La semaine dernière vous avez implanté un 1-Plus-Proche-Voisin (1-PPV). Cette semaine vous implanterez un K-PPV. Par contre, cette semaine nous ferons aussi appel à la notion d'ensembles d'entrainement et de test, ainsi qu'à la notion de surface de décision. \n",
    "\n",
    "\n",
    "- Votre première étape est de vous remémorer le fonctionnement du K-PPV.\n",
    "- Nous fournissons le cadre général où il vous faudra insérer le code de k-ppv. On y retrouve notamment des fonctions pour rendre certaines tâches (comme l'affichage des résultats) plus faciles. Cela vous permettra de vous concentrer sur la partie algorithmique de cette démonstration. Téléchargez et le notebook fourni.\n",
    "- Exécutez toutes les cellures de code en cliquant dans le menu Cell/Run all: Vous observez à la dernière cellule le fonctionnement d'un classifieur qui fait une prédiction constante (c'est-à-dire qu'il prédit, pour chaque exemple, l'étiquette 1 (bleu)).\n",
    "Familiarisez-vous avec le code des cinq sections suivantes:\n",
    "    - **Fonctions utilitaires:** définit des fonctions utiles (visualisation, évaluation)\n",
    "    - **Classe k-ppv:** c'est ici que vous devez implanter le classifieur.\n",
    "    - **Chargement et division des données:** charge un jeu de données et le divise en deux parties (train, test)\n",
    "    - **Initialisation et entraînement du classifieur:** entraîne un modèle k-PPV sur les données d'entraînement et obtient les prédictions des étiquettes pour les données de test\n",
    "    - **Matrice de confusion et surface de décision:** Affiche la matrice de confusion et visualise la surface de décision\n",
    "\n",
    "**Votre objectif pour la séance** est de comprendre le fonctionnement général du code fourni puis de compléter la fonctionkppv.compute_predictions().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette démo, nous implémenterons k-ppv à l'intérieure d'une **classe**. Vous pouvez lire ce [tutoriel](http://docs.python.org/2/tutorial/classes.html) si vous n'êtes pas à l'aise avec les classes en python. La classe `kppv` est déjà partiellement implémenté à la section **Classe k-ppv**, il ne vous reste qu'à compléter la méthode `compute_predictions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous n'avez rien à implémenter ici. Lisez simplement le code et familiarisez vous avez. Il sera possible de tester les fonctions `teste` et tout particulièrement `gridplot` à la fin du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import random\n",
    "import pylab\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction calcule la distance Minkowski entre un vecteur x et une matrice Y. Ça vous rappelle quelque chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def minkowski_mat(x,Y,p=2):\n",
    "    return (np.sum((np.abs(x-Y))**p,axis=1))**(1.0/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `conf_matrix` prend en entrée:\n",
    "\n",
    " - `etiquettesTest` - les étiquettes de test\n",
    " - `etiquettesPred` - les étiquettes prédites\n",
    "et retourne une table présentant les résultats\n",
    "\n",
    "Voir la définition d'une [matrice de confusion](http://fr.wikipedia.org/wiki/Matrice_de_confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conf_matrix(etiquettesTest, etiquettesPred):\n",
    "\n",
    "\tn_classes = max(etiquettesTest)\n",
    "\tmatrix = np.zeros((n_classes,n_classes))\n",
    "\n",
    "\tfor (test,pred) in zip(etiquettesTest, etiquettesPred):\n",
    "\t\tmatrix[test-1,pred-1] += 1\n",
    "\n",
    "\treturn matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `gridplot` prend en entrée:\n",
    "\n",
    " - `classifieur` - un classifieur tel que `kppv`\n",
    " - `train` - un ensemble d'entraînement\n",
    " - `test` - un ensemble de test\n",
    " - `n_points` - la taille de la grille pour afficher la surface de décision (x,x)\n",
    "\n",
    "Dépendamment de la puissance de calcul de votre ordinateur, le calcul des prédictions sur la grille peut être lent. Il est préférable de faire vos premiers tests avec une grille moins fine, disons de 25 par 25. Vous pourrez ensuite augmenter la valeur à 50 ou même 100 pour obtenir de plus beaux graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fonction plot\n",
    "def gridplot(classifieur,train,test,n_points=50):\n",
    "\n",
    "    train_test = np.vstack((train,test))\n",
    "    (min_x1,max_x1) = (min(train_test[:,0]),max(train_test[:,0]))\n",
    "    (min_x2,max_x2) = (min(train_test[:,1]),max(train_test[:,1]))\n",
    "\n",
    "    xgrid = np.linspace(min_x1,max_x1,num=n_points)\n",
    "    ygrid = np.linspace(min_x2,max_x2,num=n_points)\n",
    "\n",
    "\t# calcule le produit cartesien entre deux listes\n",
    "    # et met les resultats dans un array\n",
    "    thegrid = np.array(combine(xgrid,ygrid))\n",
    "\n",
    "    les_comptes = classifieur.compute_predictions(thegrid)\n",
    "    classesPred = np.argmax(les_comptes,axis=1)+1\n",
    "\n",
    "    # La grille\n",
    "    # Pour que la grille soit plus jolie\n",
    "    #props = dict( alpha=0.3, edgecolors='none' )\n",
    "    #pylab.scatter(thegrid[:,0],thegrid[:,1],c = classesPred, s=50, edgecolors='none')\n",
    "    pylab.pcolormesh(xgrid, ygrid, classesPred.reshape((n_points, n_points)).T, alpha=.3)\n",
    "\t# Les points d'entrainment\n",
    "    pylab.scatter(train[:,0], train[:,1], c = train[:,-1], marker = 'v', s=150)\n",
    "    # Les points de test\n",
    "    pylab.scatter(test[:,0], test[:,1], c = test[:,-1], marker = 's', s=150)\n",
    "\n",
    "    ## Un petit hack, parce que la fonctionalite manque a pylab...\n",
    "    h1 = pylab.plot([min_x1], [min_x2], marker='o', c = 'w',ms=5) \n",
    "    h2 = pylab.plot([min_x1], [min_x2], marker='v', c = 'w',ms=5) \n",
    "    h3 = pylab.plot([min_x1], [min_x2], marker='s', c = 'w',ms=5) \n",
    "    handles = [h1,h2,h3]\n",
    "    ## fin du hack\n",
    "\n",
    "    labels = ['grille','train','test']\n",
    "    pylab.legend(handles,labels)\n",
    "\n",
    "    pylab.axis('equal')\n",
    "    pylab.show()\n",
    "    \n",
    "## http://code.activestate.com/recipes/302478/\n",
    "def combine(*seqin):\n",
    "    '''returns a list of all combinations of argument sequences.\n",
    "for example: combine((1,2),(3,4)) returns\n",
    "[[1, 3], [1, 4], [2, 3], [2, 4]]'''\n",
    "    def rloop(seqin,listout,comb):\n",
    "        '''recursive looping function'''\n",
    "        if seqin:                       # any more sequences to process?\n",
    "            for item in seqin[0]:\n",
    "                newcomb=comb+[item]     # add next item to current comb\n",
    "                # call rloop w/ rem seqs, newcomb\n",
    "                rloop(seqin[1:],listout,newcomb)\n",
    "        else:                           # processing last sequence\n",
    "            listout.append(comb)        # comb finished, add to list\n",
    "    listout=[]                      # listout initialization\n",
    "    rloop(seqin,listout,[])         # start recursive process\n",
    "    return listout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe k-ppv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe `kppv` prend en paramètre:\n",
    "\n",
    " - `n_classes` - le nombre de classe du problème\n",
    " - `dist_func` - une fonction pour calculer la distance des points\n",
    " - `n_voisins` - le nombre de voisin à visiter \n",
    "\n",
    "La méthode `train` n'est en fait que le stockage de l'ensemble d'entraînement. Tout le travail du modèle $k$-ppv s'éffectue lors de la prédiction. \n",
    "\n",
    "La méthode `compute_predictions` prend en entré une matrice de données de test (sans étiquettes) et retourne une matrice des comptes pour chaque exemple de test. Cette matrice est donc de dimensions (n_exemple,n_classes).\n",
    "\n",
    "Vous devrez pour chaque point de l'ensemble de test :\n",
    "\n",
    " - **calculer les distances** à tous les points de l'ensemble d'entraînement (en utilisant dist_func)\n",
    " - parcourir les distances pour **trouver les $k$ voisins** du point de test courant\n",
    " - **dénombrer les voisins** correspondant à chaque classe et les sauvegarder dans les_comptes\n",
    "\n",
    "**Note :** La sortie de la méthode `kppv.compute_predictions()` doit être assez générale pour qu'on puisse l'utiliser dans plusieurs contextes. C'est pour cela qu'on vous demande que la fonction retourne une matrice qui contient des comptes pour chaque exemple de test et non pas les classes prédites pour chaque exemple de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class kppv:\n",
    "    def __init__(self,n_classes, dist_func=minkowski_mat, n_voisins=1):\n",
    "        self.n_classes = n_classes\n",
    "        self.dist_func = dist_func\n",
    "        self.n_voisins = n_voisins\n",
    "\n",
    "    # La fonction d'entrainement d'un k-PPV est juste le stockage de l'ensemble d'entrainement\n",
    "    def train(self, train_data):\n",
    "        self.train_data = train_data\n",
    "\n",
    "    ###\n",
    "    # La fonction de prédiction prend en entrée:\n",
    "    #   test_data - les données de test (sans l'étiquette)\n",
    "    # et retourne une matrice des comptes pour chaque exemple de test. \n",
    "    # Chaque rangée de cette matrice contient, pour chaque classe, le nombre \n",
    "    # de voisins appartenant à cette classe. \n",
    "    ###\n",
    "    def compute_predictions(self, test_data):\n",
    "        # Initialisation de la matrice à retourner\n",
    "        num_test = test_data.shape[0]\n",
    "        les_comptes = np.ones((num_test,self.n_classes))\n",
    "\n",
    "        # Pour chaque point de test\n",
    "        for (i,ex) in enumerate(test_data):\n",
    "            # décommentez après avoir complété la fonction\n",
    "            pass\n",
    "\n",
    "            # i est l'indice de la rangée\n",
    "            # ex est la i'eme rangée\n",
    "\n",
    "            # trouver les distances à tous les points \n",
    "            # d'entrainement (en utilisant dist_func)\n",
    "            # ---> Complétez ici\n",
    "            \n",
    "            # parcourir les données d'entrainement pour \n",
    "            # trouver les voisins du point de test courant (ex)\n",
    "            # ---> Complétez ici\n",
    "\n",
    "            # Dénombrez les voisins correspondant à chaque classe\n",
    "            # et mettez-les dans les_comptes[i,:]\n",
    "            # ---> Complétez ici\n",
    "\n",
    "        return les_comptes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et division des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de donnée `iris` est divisé en deux parties, une pour l'entraînement et l'autre pour éffectuer des tests. Il est important de mélanger aléatoirement l'ensemble de données avant d'éffectuer la division. Pouvez vous dire pourquoi? \n",
    "\n",
    "Seulement deux colonnes des données sont utilisées afin de pouvoir les visualiser en deux dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# charger iris\n",
    "iris = np.loadtxt('iris.txt')\n",
    "data = iris\n",
    "\n",
    "# Nombre de classes\n",
    "n_classes = 3\n",
    "# Nombre de points d'entrainement\n",
    "n_train = 100\n",
    "\n",
    "# Les colonnes (traits/caracteristiques) sur lesqueles on va entrainer notre modele\n",
    "# Pour que gridplot fonctionne, len(train_cols) devrait etre 2\n",
    "train_cols = [0,1]\n",
    "# L'indice de la colonne contenant les etiquettes\n",
    "target_ind = [data.shape[1] - 1]\n",
    "\n",
    "# Commenter pour avoir des resultats non-deterministes \n",
    "random.seed(3395)\n",
    "# Determiner au hasard des indices pour les exemples d'entrainement et de test\n",
    "inds = range(data.shape[0])\n",
    "random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "\n",
    "# Separer les donnees dans les deux ensembles\n",
    "train_set = data[train_inds,:]\n",
    "train_set = train_set[:,train_cols + target_ind]\n",
    "test_set = data[test_inds,:]\n",
    "test_set = test_set[:,train_cols + target_ind]\n",
    "\n",
    "# Separarer l'ensemble de test dans les entrees et les etiquettes\n",
    "test_inputs = test_set[:,:-1]\n",
    "test_labels = test_set[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation et entraînement du classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prends ici la argmax des prédictions pour avoir la classe majoritaire pour chaque exemple du test. \n",
    "\n",
    "N'oubliez pas de réexécuter cette cellule si vous avez modifié votre modèle et voulez afficher la surface de décision à la section suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nombre de voisins (k) dans k-PPV\n",
    "k = 2\n",
    "print \"On va entrainer un \",k, \"-PPV sur \", n_train, \" exemples d'entrainement\"\n",
    "\n",
    "# Créer le classifieur\n",
    "model = kppv(n_classes,dist_func = minkowski_mat, n_voisins = k)\n",
    "# L'entrainer\n",
    "model.train(train_set)\n",
    "# Obtenir ses predictions\n",
    "t1 = time.clock()\n",
    "les_comptes = model.compute_predictions(test_inputs)\n",
    "t2 = time.clock()\n",
    "print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', test_inputs.shape[0],' points de test'\n",
    "\n",
    "# Vote majoritaire (+1 puisque nos classes sont de 1 a n)\n",
    "classes_pred = np.argmax(les_comptes,axis=1)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion et surface de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On imprime ici la matrice de confusion, très utile pour comprendre quelles classes sont moins bien prédites par notre classifieur. On crée aussi un graphique qui affiche les points d'entraînement ainsi que ceux de test et la surface de décision de notre modèle. \n",
    "\n",
    "Avant de passer à la section suivante, assurez-vous que votre implémentation de $k$-ppv fonctionne bien en exécutant ce code. N'hésitez surtout pas à poser des questions si vous avez de la difficulté à interpréter la matrice de confusion et le graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Faire les tests\n",
    "# Matrice de confusion \n",
    "confmat = conf_matrix(test_labels, classes_pred)\n",
    "print 'La matrice de confusion est:'\n",
    "print confmat\n",
    "\n",
    "# Erreur de test\n",
    "sum_preds = np.sum(confmat)\n",
    "sum_correct = np.sum(np.diag(confmat))\n",
    "print \"L'erreur de test est de \", 100*(1.0 - (float(sum_correct) / sum_preds)),\"%\"\n",
    "\n",
    "# Taille de la grille = grid_size x grid_size\n",
    "grid_size = 200\n",
    "\n",
    "if len(train_cols) == 2:\n",
    "    # Surface de decision\n",
    "    t1 = time.clock()\n",
    "    gridplot(model,train_set,test_set,n_points = grid_size)\n",
    "    t2 = time.clock()\n",
    "    print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', grid_size * grid_size, ' points de la grille'\n",
    "    filename = 'grille_' + '_k=' + str(k) + '_c1=' + str(train_cols[0]) + '_c2=' + str(train_cols[1])+'.png'\n",
    "    print 'On va sauvegarder la figure dans ', filename\n",
    "    pylab.savefig(filename,format='png')\n",
    "else:\n",
    "    print 'Trop de dimensions (', len(train_cols),') pour pouvoir afficher la surface de decision'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que tous fonctionne, il est temps de faire des expérimentations pour mieux comprendre l'importance de différents facteurs. Travaillez directement sur le code précédent pour effectuer ces tests. \n",
    "\n",
    "- Variez les tailles de `train_set` et `test_set` et observez l'impact sur l'erreur de test et la surface de décision\n",
    "- Essayez $k=1,2,\\dots,10$. \n",
    "  - Est-ce que l'erreur de test change? \n",
    "  - Est-ce qu'il existe un $k$ optimal? \n",
    "  - Est-ce qu'en regardant seulement la surface de décision vous êtes en mesure de dire quel $k$ est optimal?\n",
    "- Divisez l'ensemble d'entrainement en 3 parties: `train_set`, `valid_set` et `test_set` (de taille 100, 25 et 25, par exemple). Entrainez $k$-ppv sur `train_set`, choisissez la valeur optimale de `k` en testant sur `valid_set` et obtenez un estimé de l'erreur de généralisation en testant sur `test_set`. Cette fois-ci, utilisez tous les (quatre) traits/caractéristiques/features. D'après-vous, à quoi sert l'ensemble de validation?\n",
    "  - Est-ce qu'il y a un écart entre l'erreur de validation et l'erreur de test pour le $k$ optimal trouvé avec l'ensemble de validation? Est-ce qu'il devrait y en avoir? (la réponse se trouve dans la question)\n",
    "- Décommentez la ligne `random.seed(3395)` et roulez votre code plusieurs fois pour obtenir des statistiques sur les erreurs de validation et de test. Vous pouvez écrire une boucle `for` qui exécute le même code plusieurs fois; 10 fois devrait suffire. Calculez l'écart-type et la moyenne de chaque erreur.\n",
    "\n",
    "N'hésitez pas à valider vos réponses en posant des questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
