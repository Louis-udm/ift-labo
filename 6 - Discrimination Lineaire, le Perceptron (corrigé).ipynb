{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification linéaire\n",
    "\n",
    "## Le Perceptron\n",
    "\n",
    "Durant ce travail pratique, vous allez implémenter un algorithme de classification linéaire bien connu: le perceptron. L'équation de base du perceptron est la suivante:\n",
    "\n",
    "$$f(x) = h(\\pmb{w}^T x + b)$$ \n",
    "\n",
    "où \n",
    "\n",
    "$$ \n",
    " h(a) = \\left\\{ \n",
    "  \\begin{array}{l l}\n",
    "    ~1 & \\quad \\text{si} ~ a > 0\\\\\n",
    "    -1 & \\quad \\text{sinon}\n",
    "  \\end{array} \\right. $$\n",
    "\n",
    "et $x$ est un exemple à prédire, $\\pmb{w}$ est un vecteur de poids et $b$ est un biais. $\\pmb{w}$ et $b$ sont les paramètres que nous allons devoir apprendre.\n",
    "\n",
    "## Apprentissage des paramètres pour le perceptron\n",
    "\n",
    "*Dans cette partie vous allez calculer les formules de mise à jour des paramètres $\\pmb{w}$ et $b$*\n",
    "\n",
    "### Fonction objectif\n",
    "\n",
    "L'algorithme d'apprentissage du perceptron correspond à une descente de gradient sur l’objectif suivant:\n",
    "$$J_{perceptron}(\\theta) = \\frac{1}{n} \\sum_{i=1}^n I_{\\{(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0\\}}(-(\\pmb{w}^T x^{(i)} + b)t^{(i)})$$\n",
    "\n",
    "En fait cet objectif va juste compter le nombre d'exemple qui sont mal classifiés pour des paramètres $\\pmb{w}$ et $b$ donnés. Si on réduit la valeur de la fonction objectif, alors on réduit le nombre d'exemple mal classifiés, donc on obtient un meilleur classifieur.\n",
    "\n",
    "### Descente de gradient stochastique\n",
    "\n",
    "Pour obtenir l'algorithme d'apprentissage pour le perceptron, on va utiliser la méthode de descente de gradient stochastique, c'est à dire qu'on va mettre à jour les poids de manière à ce qu'à chaque itération, on réduise l'objectif calculé sur **un** exemple, en suivant la direction donnée par l'opposé du gradient.\n",
    "\n",
    "À vous de jouer:\n",
    "\n",
    "1. Exprimez la fonction objectif pour un seul exemple\n",
    "2. Exprimez les dérivées partielles $\\frac{\\partial J^{(i)}}{\\partial b} et \\frac{\\partial J^{(i)}}{\\partial \\pmb{w}}$\n",
    "\n",
    "Aide: séparer les cas $(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0$ et $(\\pmb{w}^T x^{(i)} + b)t^{(i)} \\geq 0$\n",
    "\n",
    "La fonction objectif pour l'exemple $i$ est:\n",
    "$$J^{(i)} = I_{\\{(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0\\}}(-(\\pmb{w}^T x^{(i)} + b)t^{(i)})$$\n",
    "\n",
    "Exprimons les dérivées partielles, dans le cas où $(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0$, on obtient:\n",
    "$$\\frac{\\partial J^{(i)}}{\\partial b} = -t^{(i)}$$\n",
    "$$\\frac{\\partial J^{(i)}}{\\partial \\pmb{w}} = -x^{(i)} t^{(i)}$$\n",
    "Dans l'autre cas ($(\\pmb{w}^T x^{(i)} + b)t^{(i)} \\geq 0$), les deux dérivées partielles sont nulles car $J^{(i)}$ est constant ($J^{(i)} = 0$)\n",
    "\n",
    "### Algorithme d'entrainement\n",
    "\n",
    "L'algorithme d'apprentissage est donc:\n",
    "\n",
    " - boucler sur les exemples un par un\n",
    " - pour chaque exemple mettre à jour les poids en utilisant : $b \\leftarrow b - \\eta \\frac{\\partial J^{(i)}}{\\partial b}$ et $\\pmb{w} \\leftarrow \\pmb{w} - \\eta \\frac{\\partial J^{(i)}}{\\partial \\pmb{w}}$\n",
    "\n",
    "On peut ajouter une condition d'arrêt :\n",
    "\n",
    " - si tous les exemples d'entrainement sont bien classés on s'arrête. Dans ce cas $J_{perceptron}(\\theta) = 0$ et les dérivées partielles sont nulles, donc on n'apprend plus rien.\n",
    "\n",
    "## Travail Pratique\n",
    "\n",
    "*Dans cette partie vous allez implémenter les formules obtenues ci-dessus*\n",
    "\n",
    "### Préparation des données\n",
    "\n",
    "Dans ce travail pratique on va travailler sur le dataset iris. On va utiliser seulement 2 classes: les iris avec les étiquettes 1 et 2, que l'on va transformer en 1 et -1 pour les besoins du perceptron. On va également utiliser uniquement 2 traits par iris, afin de pouvoir visualiser l'algorithme.\n",
    "\n",
    "Voici le code qui prépare les données. N'hésitez pas à regarder les *shapes* des différents sets pour voir comment les données sont préparées!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a48d9924a95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#On commence par charger iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-105>\u001b[0m in \u001b[0;36mpylab\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mpylab\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mimport_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_import_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclobbered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pylab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Populating the interactive namespace from numpy and matplotlib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_pylab\u001b[0;34m(self, gui, import_all, welcome_message)\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylabtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_pylab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# We want to prevent the loading of pylab to pollute the user's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \"\"\"\n\u001b[1;32m   2934\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \"\"\"\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "#On commence par charger iris\n",
    "iris = np.loadtxt('iris.txt')\n",
    "data = iris\n",
    "\n",
    "# On se limite au cas de la classification BINAIRE donc on va seulement garder \n",
    "# données des 2 premières classes.\n",
    "# Ici on garde juste les exemples avec l'etiquette 1 et 2.\n",
    "data = data[data[:,-1]<3,:]\n",
    "# Ici on transforme chaque etiquette qui est egale a 2 en -1, pour avoir les \n",
    "# mêmes étiquettes que dans la formulation standard du perceptron (1 et -1).\n",
    "data[data[:,-1]==2,-1] = -1\n",
    "\n",
    "# On se limite à des données dont la dimension est 2, de façon à pouvoir visualiser\n",
    "# la frontière de decision avec la fonction gridplot.\n",
    "train_cols = [2,3]\n",
    "# Une variable pour contenir l'indice de la colonne correspondant aux étiquettes.\n",
    "target_ind = [data.shape[1] - 1]\n",
    "\n",
    "# Nombre de classes\n",
    "n_classes = 2\n",
    "# Nombre de points d'entrainement\n",
    "n_train = 75\n",
    "\n",
    "# Commenter pour avoir des resultats non-deterministes \n",
    "np.random.seed(2)\n",
    "\n",
    "# Déterminer au hasard des indices pour les exemples d'entrainement et de test\n",
    "inds = range(data.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "    \n",
    "# Séparer les donnees dans les deux ensembles: entrainement et test.\n",
    "train_set = data[train_inds,:]  # garder les bonnes lignes\n",
    "train_set = train_set[:,train_cols + target_ind]  # garder les bonnes colonnes\n",
    "test_set = data[test_inds,:]\n",
    "test_set = test_set[:,train_cols + target_ind]\n",
    "\n",
    "# Sépararer l'ensemble de test: entrées et étiquettes.\n",
    "test_inputs = test_set[:,:-1]\n",
    "test_labels = test_set[:,-1]\n",
    "\n",
    "# Le taux d'apprentissage\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###La classe Perceptron###\n",
    "\n",
    "On introduit la classe *Perceptron*. Comme d'habitude, c'est un algorithme qui possède une fonction *train* pour entraîner l'algorithme à partir du *train_set* et une fonction *compute_prediction*, qui prédit les classes de chaque exemple de *test_inputs*.\n",
    "\n",
    "Pour ce travail pratique vous devez:\n",
    "\n",
    "1. Compléter la fonction *train* de la classe *Perceptron*.\n",
    "2. Compléter la fonction *compute_prediction* de la classe *Perceptron*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-2-867ed11ba3a9>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-867ed11ba3a9>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    print 'Entraînement ...'\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, mu):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe. Prend les paramètres données à la\n",
    "        constuction de la classe et initialise ses attribues.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : float\n",
    "            Taux d'apprentissage\n",
    "        \"\"\"\n",
    "        self.mu = mu\n",
    "\n",
    "    def plot_function(self, train_data, title):\n",
    "        plt.figure()\n",
    "        d1 = train_data[train_data[:, -1] > 0]\n",
    "        d2 = train_data[train_data[:, -1] < 0]\n",
    "        plt.scatter(d1[:, 0], d1[:, 1], c='b', label='classe +1')\n",
    "        plt.scatter(d2[:, 0], d2[:, 1], c='g', label='classe -1')\n",
    "        x = np.linspace(-10, 10, 100)\n",
    "        y = -(self.weights[0]*x + self.bias)/self.weights[1]\n",
    "        plt.plot(x, y, c='r', lw=2, label='y = -(w1*x + b1)/w2')\n",
    "        plt.xlim(np.min(train_data[:, 0]) - 0.5, np.max(train_data[:, 0]) + 0.5)\n",
    "        plt.ylim(np.min(train_data[:, 1]) - 0.5, np.max(train_data[:, 1]) + 0.5)\n",
    "        plt.grid()\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, train_data, max_iter=10):\n",
    "        \"\"\"\n",
    "        Entraine le modèle d'apprentissage à partir d'une matrice de données,\n",
    "        en faisant un maximum de max_iter sur le set d'entraînement.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : array\n",
    "            matrice de dimension (n,d+1) où n est le nombre d'exemples et \n",
    "            d le nombre de dimensions. L'index d+1 de change ligne représente\n",
    "            la classe de l'exemple de cette ligne.\n",
    "        max_iter : int\n",
    "            Nombre maximum d'itérations sur le set d'entrainement (défaut 10).\n",
    "        \"\"\"\n",
    "        # 1) Initialisation des paramètres. \n",
    "        # Initialisez les poids à de petites valeurs et le biais à 0.\n",
    "        self.weights = np.random.randn(train_data.shape[1]-1) \n",
    "        self.bias = 0\n",
    "         \n",
    "        # 2) Entrainement\n",
    "        # Implémentez l'algorithme présenté ci-dessus.\n",
    "        # iterations est le nombre d'itérations effectuées sur le set d'entraînement\n",
    "        # count est le nombre d'éléments mal classés.\n",
    "        print 'Entraînement ...'\n",
    "        iteration = 0\n",
    "        while iteration < max_iter:\n",
    "            self.plot_function(train_data, 'Iteration no: ' + str(iteration))\n",
    "            count = 0\n",
    "            for i in xrange(train_data.shape[0]):\n",
    "                # implémentez le test d'erreur de classification\n",
    "                # et implémentez la mise à jour des poids\n",
    "                # sans oublier d'incrémenter les compteurs count et époque\n",
    "                # afin que l'entraînement termine un jour!\n",
    "                if (np.dot(self.weights, train_data[i][:-1]) + self.bias) * train_data[i][-1] < 0:\n",
    "                    self.weights += self.mu * train_data[i][:-1] * train_data[i][-1]\n",
    "                    self.bias += self.mu * train_data[i][-1]\n",
    "                    count += 1\n",
    "            if count == 0:\n",
    "                break\n",
    "            iteration += 1\n",
    "        print 'Entraînement terminé!'\n",
    "        print \"L'erreur d'entraînement est de \", float(count)/train_data.shape[0], \"%.\"\n",
    "\n",
    "    def compute_predictions(self, test_data):\n",
    "        \"\"\"\n",
    "        Calcule les prédictions à partir d'une matrice de test. Donne en\n",
    "        sortie une prédictions pour chaque classe.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        test_data : array\n",
    "            matrice de dimension (n,d) où n est le nombre d'exemples et\n",
    "            d le nombre de dimensions\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "            tableau de dimension (n) où n est le nombre d'exemples de test.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A COMPLÉTER!\n",
    "        # Cette fonction doit utiliser les paramètres appris pour calculer\n",
    "        # la valeur de sortie pour les exemples de test_data (un exemple\n",
    "        # par ligne, seulement les traits).\n",
    "  \n",
    "        # 1) Vous devez calculer la vraie valeur de sorties.\n",
    "        predictions = np.zeros(test_data.shape[0])\n",
    "        for i in xrange(test_data.shape[0]):\n",
    "            predictions[i] = np.dot(self.weights, test_data[i]) + self.bias \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Entraînement du modèle###\n",
    "\n",
    "Maintenant que la classe *Perceptron* est complétée, on peut l'entraîner. Un graphe va s'afficher pour chaque itération effectuées sur le set d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Créer et entrainer le modele\n",
    "model_perceptron = Perceptron(mu)\n",
    "model_perceptron.train(train_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test du modèle###\n",
    "\n",
    "Maintenant que le modèle est entraîné, on peut le tester!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtenir les classes prédites sur l'ensemble de test\n",
    "predictions = model_perceptron.compute_predictions(test_inputs)\n",
    "\n",
    "# Convertir les sorties en classe. On prend le signe.\n",
    "classes_pred = np.sign(predictions)\n",
    "   \n",
    "# Mesurer la performance.\n",
    "err = 1.0 - np.mean(test_labels==classes_pred)\n",
    "\n",
    "model_perceptron.plot_function(test_set, 'Test data')\n",
    "print \"L'eureur de test est de \", 100.0 * err,\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Si vous avez terminé...###\n",
    "\n",
    "Si vous avez terminé, vous pouvez essayer de varier les différents paramètres, par exemple:\n",
    "\n",
    "1. Varier $mu$. Quel est son impact sur le temps d'entraînement? Et sur les performances?\n",
    "2. Utiliser d'autres traits des iris (par exemple [1,3] à la place de [2,3]).\n",
    "3. Varier la taille du set d'entraînement. Y a-t-il un impact sur les performances?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
