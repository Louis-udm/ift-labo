{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification linéaire\n",
    "\n",
    "## Le Perceptron\n",
    "\n",
    "Durant ce travail pratique, vous allez implémenter un algorithme de classification linéaire bien connu: le perceptron. L'équation de base du perceptron est la suivante:\n",
    "\n",
    "$$f(x) = h(\\pmb{w}^T x + b)$$ \n",
    "\n",
    "où \n",
    "\n",
    "$$ \n",
    " h(a) = \\left\\{ \n",
    "  \\begin{array}{l l}\n",
    "    ~1 & \\quad \\text{si} ~ a > 0\\\\\n",
    "    -1 & \\quad \\text{sinon}\n",
    "  \\end{array} \\right. $$\n",
    "\n",
    "et $x$ est un exemple à prédire, $\\pmb{w}$ est un vecteur de poids et $b$ est un biais. $\\pmb{w}$ et $b$ sont les paramètres que nous allons devoir apprendre.\n",
    "\n",
    "## Apprentissage des paramètres pour le perceptron\n",
    "\n",
    "*Dans cette partie vous allez calculer les formules de mise à jour des paramètres $\\pmb{w}$ et $b$*\n",
    "\n",
    "### Fonction objectif\n",
    "\n",
    "L'algorithme d'apprentissage du perceptron correspond à une descente de gradient sur l’objectif suivant:\n",
    "$$J_{perceptron}(\\theta) = \\frac{1}{n} \\sum_{i=1}^n I_{\\{(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0\\}}(-(\\pmb{w}^T x^{(i)} + b)t^{(i)})$$\n",
    "\n",
    "En fait cet objectif va juste compter le nombre d'exemple qui sont mal classifiés pour des paramètres $\\pmb{w}$ et $b$ donnés. Si on réduit la valeur de la fonction objectif, alors on réduit le nombre d'exemple mal classifiés, donc on obtient un meilleur classifieur.\n",
    "\n",
    "### Descente de gradient stochastique\n",
    "\n",
    "Pour obtenir l'algorithme d'apprentissage pour le perceptron, on va utiliser la méthode de descente de gradient stochastique, c'est à dire qu'on va mettre à jour les poids de manière à ce qu'à chaque itération, on réduise l'objectif calculé sur **un** exemple, en suivant la direction donnée par l'opposé du gradient.\n",
    "\n",
    "À vous de jouer:\n",
    "\n",
    "1. Exprimez la fonction objectif pour un seul exemple\n",
    "2. Exprimez les dérivées partielles $\\frac{\\partial J^{(i)}}{\\partial b} et \\frac{\\partial J^{(i)}}{\\partial \\pmb{w}}$ \n",
    "\n",
    "Aide: séparer les cas $(\\pmb{w}^T x^{(i)} + b)t^{(i)} < 0$ et $(\\pmb{w}^T x^{(i)} + b)t^{(i)} \\geq 0$\n",
    "\n",
    "### Algorithme d'entrainement\n",
    "\n",
    "L'algorithme d'apprentissage est donc:\n",
    "\n",
    " - boucler sur les exemples un par un\n",
    " - pour chaque exemple mettre à jour les poids en utilisant : $b \\leftarrow b - \\eta \\frac{\\partial J^{(i)}}{\\partial b}$ et $\\pmb{w} \\leftarrow \\pmb{w} - \\eta \\frac{\\partial J^{(i)}}{\\partial \\pmb{w}}$\n",
    "\n",
    "On peut ajouter une condition d'arrêt :\n",
    "\n",
    " - si tous les exemples d'entrainement sont bien classés on s'arrête. Dans ce cas $J_{perceptron}(\\theta) = 0$ et les dérivées partielles sont nulles, donc on n'apprend plus rien.\n",
    "\n",
    "## Travail Pratique\n",
    "\n",
    "*Dans cette partie vous allez implémenter les formules obtenues ci-dessus*\n",
    "\n",
    "### Préparation des données\n",
    "\n",
    "Dans ce travail pratique on va travailler sur le dataset iris. On va utiliser seulement 2 classes: les iris avec les étiquettes 1 et 2, que l'on va transformer en 1 et -1 pour les besoins du perceptron. On va également utiliser uniquement 2 traits par iris, afin de pouvoir visualiser l'algorithme.\n",
    "\n",
    "Voici le code qui prépare les données. N'hésitez pas à regarder les *shapes* des différents sets pour voir comment les données sont préparées!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "#On commence par charger iris\n",
    "iris = np.loadtxt('iris.txt')\n",
    "data = iris\n",
    "\n",
    "# On se limite au cas de la classification BINAIRE donc on va seulement garder \n",
    "# données des 2 premières classes.\n",
    "# Ici on garde juste les exemples avec l'etiquette 1 et 2.\n",
    "data = data[data[:,-1]<3,:]\n",
    "# Ici on transforme chaque etiquette qui est egale a 2 en -1, pour avoir les \n",
    "# mêmes étiquettes que dans la formulation standard du perceptron (1 et -1).\n",
    "data[data[:,-1]==2,-1] = -1\n",
    "\n",
    "# On se limite à des données dont la dimension est 2, de façon à pouvoir visualiser\n",
    "# la frontière de decision avec la fonction gridplot.\n",
    "train_cols = [2,3]\n",
    "# Une variable pour contenir l'indice de la colonne correspondant aux étiquettes.\n",
    "target_ind = [data.shape[1] - 1]\n",
    "\n",
    "# Nombre de classes\n",
    "n_classes = 2\n",
    "# Nombre de points d'entrainement\n",
    "n_train = 75\n",
    "\n",
    "# Commenter pour avoir des resultats non-deterministes \n",
    "np.random.seed(2)\n",
    "\n",
    "# Déterminer au hasard des indices pour les exemples d'entrainement et de test\n",
    "inds = range(data.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "    \n",
    "# Séparer les donnees dans les deux ensembles: entrainement et test.\n",
    "train_set = data[train_inds,:]  # garder les bonnes lignes\n",
    "train_set = train_set[:,train_cols + target_ind]  # garder les bonnes colonnes\n",
    "test_set = data[test_inds,:]\n",
    "test_set = test_set[:,train_cols + target_ind]\n",
    "\n",
    "# Sépararer l'ensemble de test: entrées et étiquettes.\n",
    "test_inputs = test_set[:,:-1]\n",
    "test_labels = test_set[:,-1]\n",
    "\n",
    "# Le taux d'apprentissage\n",
    "eta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Perceptron\n",
    "\n",
    "On introduit la classe *Perceptron*. Comme d'habitude, c'est un algorithme qui possède une fonction *train* pour entraîner l'algorithme à partir du *train_set* et une fonction *compute_prediction*, qui prédit les classes de chaque exemple de *test_inputs*.\n",
    "\n",
    "Pour ce travail pratique vous devez:\n",
    "\n",
    "1. Compléter la fonction *train* de la classe *Perceptron*.\n",
    "2. Compléter la fonction *compute_prediction* de la classe *Perceptron*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, eta):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe. Prend les paramètres données à la\n",
    "        constuction de la classe et initialise ses attribues.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        eta : float\n",
    "            Taux d'apprentissage\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "\n",
    "    def plot_function(self, train_data, title):\n",
    "        plt.figure()\n",
    "        d1 = train_data[train_data[:, -1] > 0]\n",
    "        d2 = train_data[train_data[:, -1] < 0]\n",
    "        plt.scatter(d1[:, 0], d1[:, 1], c='b', label='classe +1')\n",
    "        plt.scatter(d2[:, 0], d2[:, 1], c='g', label='classe -1')\n",
    "        x = np.linspace(-10, 10, 100)\n",
    "        y = -(self.weights[0]*x + self.bias)/self.weights[1]\n",
    "        plt.plot(x, y, c='r', lw=2, label='y = -(w1*x + b1)/w2')\n",
    "        plt.xlim(np.min(train_data[:, 0]) - 0.5, np.max(train_data[:, 0]) + 0.5)\n",
    "        plt.ylim(np.min(train_data[:, 1]) - 0.5, np.max(train_data[:, 1]) + 0.5)\n",
    "        plt.grid()\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, train_data, max_iter=10):\n",
    "        \"\"\"\n",
    "        Entraine le modèle d'apprentissage à partir d'une matrice de données,\n",
    "        en faisant un maximum de max_iter sur le set d'entraînement.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : array\n",
    "            matrice de dimension (n,d+1) où n est le nombre d'exemples et \n",
    "            d le nombre de dimensions. L'index d+1 de change ligne représente\n",
    "            la classe de l'exemple de cette ligne.\n",
    "        max_iter : int\n",
    "            Nombre maximum d'itérations sur le set d'entrainement (défaut 10).\n",
    "        \"\"\"\n",
    "        # 1) Initialisation des paramètres. \n",
    "        # Initialisez les poids à de petites valeurs et le biais à 0.\n",
    "        self.weights = #compléter\n",
    "        self.bias = #compléter\n",
    "         \n",
    "        # 2) Entrainement\n",
    "        # Implémentez l'algorithme présenté ci-dessus.\n",
    "        # iterations est le nombre d'itérations effectuées sur le set d'entraînement\n",
    "        # count est le nombre d'éléments mal classés.\n",
    "        print 'Entraînement ...'\n",
    "        iteration = 0\n",
    "        while iteration < max_iter:\n",
    "            self.plot_function(train_data, 'Iteration no: ' + str(iteration))\n",
    "            count = 0\n",
    "            # implémentez l'algorithme d'entrainement ici!\n",
    "            \n",
    "            iteration += 1\n",
    "        print 'Entraînement terminé!'\n",
    "        print \"L'erreur d'entraînement est de \", float(count)/train_data.shape[0], \"%.\"\n",
    "\n",
    "    def compute_predictions(self, test_data):\n",
    "        \"\"\"\n",
    "        Calcule les prédictions à partir d'une matrice de test. Donne en\n",
    "        sortie une prédictions pour chaque classe.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        test_data : array\n",
    "            matrice de dimension (n,d) où n est le nombre d'exemples et\n",
    "            d le nombre de dimensions\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "            tableau de dimension (n) où n est le nombre d'exemples de test.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A COMPLÉTER!\n",
    "        # Cette fonction doit utiliser les paramètres appris pour calculer\n",
    "        # la valeur de sortie pour les exemples de test_data (un exemple\n",
    "        # par ligne, seulement les traits).\n",
    "  \n",
    "        # 1) Vous devez calculer la vraie valeur de sorties.\n",
    "        predictions = np.zeros(test_data.shape[0])\n",
    "        # compléter ici\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle\n",
    "\n",
    "Maintenant que la classe *Perceptron* est complétée, on peut l'entraîner. Un graphe va s'afficher pour chaque itération effectuées sur le set d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Créer et entrainer le modele\n",
    "model_perceptron = Perceptron(eta)\n",
    "model_perceptron.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du modèle\n",
    "\n",
    "Maintenant que le modèle est entraîné, on peut le tester!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtenir les classes prédites sur l'ensemble de test\n",
    "predictions = model_perceptron.compute_predictions(test_inputs)\n",
    "\n",
    "# Convertir les sorties en classe. On prend le signe.\n",
    "classes_pred = np.sign(predictions)\n",
    "   \n",
    "# Mesurer la performance.\n",
    "err = 1.0 - np.mean(test_labels==classes_pred)\n",
    "\n",
    "model_perceptron.plot_function(test_set, 'Test data')\n",
    "print \"L'eureur de test est de \", 100.0 * err,\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si vous avez terminé...\n",
    "\n",
    "Si vous avez terminé, vous pouvez essayer de varier les différents paramètres, par exemple:\n",
    "\n",
    "1. Varier $\\eta$. Quel est son impact sur le temps d'entraînement? Et sur les performances?\n",
    "2. Utiliser d'autres traits des iris (par exemple [1,3] à la place de [2,3]).\n",
    "3. Varier la taille du set d'entraînement. Y a-t-il un impact sur les performances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
