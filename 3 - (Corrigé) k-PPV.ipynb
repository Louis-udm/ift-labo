{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Un peu de th\u00e9orie sur k-PPV"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Motivation intuitive"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "L'algorithme des $k$ plus proches voisins ($k$-PPV) est certainement un des algorithmes les plus simples d'apprentissage automatique. Il est motiv\u00e9 par l'id\u00e9e que des *entr\u00e9es* $x_t$ semblables devraient avoir des *cibles* $y_t$ semblables. Ainsi, pour bien d\u00e9finir un algorithme $k$-PPV, il suffit de d\u00e9finir ce que veut dire *semblable* dans le contexte des entr\u00e9es et de d\u00e9finir l'influence de ces voisins sur la pr\u00e9diction de la cible pour une entr\u00e9e de test.\n",
      "\n",
      "Donc, pour obtenir une pr\u00e9diction de la cible pour une entr\u00e9e de test $x$, il suffit de trouver les k plus proches voisins selon une m\u00e9trique d\u00e9terminant jusqu'\u00e0 quel point des entr\u00e9es sont semblables (par exemple, la distance eucl\u00e9dienne ou norme $L^2$, ou de fa\u00e7on plus g\u00e9n\u00e9rale la norme $L^p$ de Minkowski) et d'utiliser ces $k$ plus proches voisins pour pr\u00e9dire la cible de $x$. Dans un probl\u00e8me de classification, la pr\u00e9diction correspond \u00e0 la classe majoritaire parmi les $k$ plus proches voisins, i.e. que l'ensemble des $k$ plus proches voisins votent pour la classe correspondant \u00e0 leur cible respective et la classe recueillant le plus de vote est choisie en tant que pr\u00e9diction par l'algorithme."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Formalisation math\u00e9matique"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Soit\n",
      "\n",
      "* $x$ une entr\u00e9e de test\n",
      "* $m$ le nombre de classes\n",
      "* $D_n = \\{(x_t,y_t)\\}_{t=1}^n$ l'ensemble d'entra\u00eenement, o\u00f9 $y \\in Y=\\{1,\\dots,m\\}$ correspond \u00e0 l'identit\u00e9 de la classe cible de l'entr\u00e9e $x_t$\n",
      "* $d(\\dot{},\\dot{})$ une fonction de distance\n",
      "* $V(x,T,d(\\dot{},\\dot{}),k)$ l'ensemble des $k$ plus proches voisins de $x$ parmi les entr\u00e9es de $T$ ainsi que leur cible associ\u00e9e"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La pr\u00e9diction de classification par l'algorithme des k plus proches voisins est donc:\n",
      "\n",
      "> $$f(x) = {\\mbox{arg max}} \\left( \\frac{1}{k} \\sum_{(x_i,y_i) \\in V(x)} \\mathrm{onehot}_{m}(y_i) \\right)$$\n",
      "\n",
      "Une fonction de distance couramment utilis\u00e9e est la distance eucl\u00e9dienne:\n",
      "\n",
      "> $$d(a,b)= \\sqrt{\\sum_{i=1}^d(a_i-b_i)^2}$$\n",
      "\n",
      "qui est un cas sp\u00e9cifique, avec $p=2$, de la norme $L^p$ de Minkowski:\n",
      "\n",
      "> $$d(a,b)= \\left(\\sum_{i=1}^d|a_i-b_i|^p\\right)^\\frac{1}{p}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pseudo-code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On d\u00e9finit un algorithme d'apprentissage en pr\u00e9cisant sa proc\u00e9dure d'entra\u00eenement et de pr\u00e9diction pour une nouvelle entr\u00e9e de test. \u00c9tant donn\u00e9 que la proc\u00e9dure d'entra\u00eenement de l'algorithme $k$-PPV consiste simplement \u00e0 mettre en m\u00e9moire l'ensemble d'entra\u00eenement $D_n$, voici donc la proc\u00e9dure de pr\u00e9diction:\n",
      "\n",
      "    definition k-PPV(x)\n",
      "        pour i=1 \u00e0 m\n",
      "            faire \n",
      "            c[i]=0\n",
      "            \n",
      "        pour i=1 \u00e0 k\n",
      "            faire \n",
      "            voisins[i] = Null\n",
      "            dists[i] = inf\n",
      "    \n",
      "        pour t=1 \u00e0 n\n",
      "            faire\n",
      "            dt = d(X[t],x)\n",
      "            j = argmax(dists)\n",
      "            si dt < dists[j]\n",
      "                alors\n",
      "                voisins[j] = (X[t],Y[t])\n",
      "                dists[j] = dt\n",
      "                \n",
      "        pour i=1 \u00e0 k\n",
      "            faire\n",
      "            si voisins[i]!=Null\n",
      "                alors\n",
      "                X[i],Y[i] = voisins[i]\n",
      "                c[Y[i]] = c[Y[i]] + 1\n",
      "                \n",
      "        retourner argmax(c)\n",
      "        \n",
      "Lorsque `dist` est une liste non tri\u00e9e, la proc\u00e9dure de pr\u00e9diction s'ex\u00e9cute en temps $O(n(k+d))$. Il est cependant possible d'obtenir un temps d'ex\u00e9cution dans $O(n(log(k)+d))$, en utilisant une queue de priorit\u00e9 (monceau)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Impl\u00e9mentations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Voici quelques applets accessibles sur le web, permettant de visualiser les propri\u00e9t\u00e9s de l'algorithme des k plus proches voisins:\n",
      "\n",
      " \n",
      "\n",
      "* Classification binaire\n",
      "  1. http://www.cs.cmu.edu/~zhuxj/courseproject/knndemo/KNN.html\n",
      "  2. http://www.cs.technion.ac.il/~rani/LocBoost/index.html\n",
      "* Estimation de densit\u00e9\n",
      "  1. http://www.eee.metu.edu.tr/~alatan/Courses/Demo/AppletKnn.html\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "La mise en pratique!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "En guise d'introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On vous demande de concevoir un algorithme d'apprentissage permettant d'identifier des fleurs sur un convoyeur. Il s'agit de trois vari\u00e9t\u00e9s d'iris. Le convoyeur est dot\u00e9 d'une cam\u00e9ra capable de mesurer les longueurs et largeurs des p\u00e9tales et s\u00e9pales de chaque fleur. C'est \u00e0 partir de ces caract\u00e9ristiques (traits) que vous devez d\u00e9terminer la sorte de chaque fleur (la classe). Vous ne connaissez rien aux fleurs! Fort heureusement vous disposez d'un ensemble d'entra\u00eenement associant \u00e0 divers exemples de mesures d'iris la bonne vari\u00e9t\u00e9 (classe). Arm\u00e9 de l'algo 1-PPV et de Python vous foncez t\u00eate baiss\u00e9e."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comment calculer une distance $L^p$ (Minkowski) entre deux vecteurs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Passons maintenant aux choses s\u00e9rieuses. On d\u00e9sire obtenir la fonction `minkowski_vec` qui nous permet de comparer deux fleurs sur la base de leurs traits. Compl\u00e9tez la fonction suivante, puis testez-la sur deux exemples d'iris (revoir au besoin la d\u00e9mo 2 pour l'acc\u00e8s et l'importation de l'ensemble de donn\u00e9es iris). \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def minkowski_vec(x1,x2,p=2.0):\n",
      "    diff = (np.abs(x1-x2)**p).sum()**(1.0/p)\n",
      "    return diff\n",
      "\n",
      "# pour tester\n",
      "a = np.ones((10,5))\n",
      "b = np.zeros((10,5))\n",
      "print minkowski_vec(a[0],b[0])\n",
      "print minkowski_vec(a[0],a[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.2360679775\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rappelez-vous la [d\u00e9finition](http://en.wikipedia.org/wiki/Minkowski_distance) de la distance. \n",
      "\n",
      "**Chose importante:** on peut calculer cette distance en it\u00e9rant sur chaque composante de x1 et x2, et en calculant la somme apr\u00e8s, ou on peut profiter du fait que la plupart (ou m\u00eame toutes) des op\u00e9rations math\u00e9matiques (abs, +, -, \\*\\* etc.) sur des structures de donn\u00e9es it\u00e9rables (listes, vecteurs/matrices) produisent des r\u00e9sultats \u00e9quivalents \u00e0 l'application d'une boucle for, mais en beaucoup moins de temps (on parle des langages interpr\u00e9t\u00e9s comme Python). Par exemple, on peut calculer la somme de la diff\u00e9rence des valeurs absolues de x1 et x2 comme\n",
      "\n",
      "    s = 0\n",
      "    for i in range(x1.shape[0]):\n",
      "        s = s + abs(x1[i] - x2[i])\n",
      "\n",
      "ou simplement\n",
      "\n",
      "    s = numpy.sum(numpy.abs(x1 - x2))\n",
      "\n",
      "En plus d'\u00eatre plus compacte, la deuxi\u00e8me option est beaucoup plus rapide (parce qu'elle fait appel \u00e0 une impl\u00e9mentation efficace de sum et abs en C++).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comment calculer une distance $L^p$ entre un vecteur et une matrice"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Il nous faut aussi une fonction qui va nous permettre de comparer une fleur avec tout un ensemble de fleurs, sur la base de leurs traits. On va maintenant modifier la fonction `minkowski` pour calculer une *distance* $L^p$ entre un vecteur et une matrice (c.a.d. une fonction qui va nous retourner un vecteur de distances $L^p$)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minkowski_mat(x,Y,p=2.0):\n",
      "    dist = (np.abs(x-Y)**p).sum(1)**(1.0/p)\n",
      "    return dist\n",
      "\n",
      "# pour tester\n",
      "a = np.ones((10,5))\n",
      "b = np.zeros((10,5))\n",
      "print minkowski_mat(a,b)\n",
      "print minkowski_mat(a,a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.23606798  2.23606798  2.23606798  2.23606798  2.23606798  2.23606798\n",
        "  2.23606798  2.23606798  2.23606798  2.23606798]\n",
        "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comme pour `minkowski_vec`, il y a deux mani\u00e8res de proc\u00e9der:\n",
      " \n",
      "1. *Simple et inefficace:* en \u00e9crivant une boucle qui appelle la fonction `minkowski_vec(x,Y[i,:],p)` et garde les r\u00e9sultats dans le vecteur `dist`.\n",
      "2. *Plus compliqu\u00e9 mais plus efficace:* en utilisant le fait que `numpy` fait quelque chose d'intelligent quand il \u00e9value `x-Y`, car il retourne une matrice qui contient le vecteur `x-Y[i,:]` sur la rang\u00e9e $i$ (le m\u00e9canisme qui rend cela possible s'appelle *broadcasting*). Voici une solution:\n",
      "\n",
      "        def minkowski_mat(x,Y,p=2.0):\n",
      "            diff = x - Y # diff sera une matrice\n",
      "            absdiff = abs(diff) # absdiff sera une matrice\n",
      "            powdiff = absdiff**p # powdiff sera une matrice\n",
      "            s = numpy.sum(powdiff,axis=1) # calcule la somme de chaque rang\u00e9e, s est un vecteur\n",
      "            dist = s**(1.0/p) # dist sera un vecteur aussi\n",
      "            return dist\n",
      "\n",
      "    ou bien\n",
      "\n",
      "        def minkowski_mat(x,Y,p=2.0):\n",
      "            return (numpy.sum((abs(x-Y))**p,axis=1))**(1.0/p) "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Encore une fois, chose importante \u00e0 retenir:  \n",
      "**la  grande majorit\u00e9 des op\u00e9rations vecteur-vecteur, vecteur-matrice ou bien matrice-matrice seront beaucoup plus efficaces en utilisant les\n",
      "op\u00e9rateurs numpy au lieu d'une boucle for.** (les raisons \u00e9tant,  entre autres, le fait que python est un langage interpr\u00e9t\u00e9 et que numpy a  des impl\u00e9mentations tr\u00e8s efficace pour certaines op\u00e9rations vectorielles).\n",
      " \n",
      "Vous avez peut-\u00eatre remarqu\u00e9 que la diff\u00e9rence entre les impl\u00e9mentations efficaces de `minkowski_vec` et `minkowski_mat` est seulement la partie: `axis=1`. L'exercice est de comprendre pourquoi il est n\u00e9cessaire de sp\u00e9cifier sur quel *axe* on va faire la somme."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1-PPV"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Enfin, nous y sommes! Compl\u00e9tez la fonction suivante et v\u00e9rifiez son efficacit\u00e9. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ppv(x,data,p=2): \n",
      "    caract = data[:,:-1]\n",
      "    cibles = data[:,-1]\n",
      "    dist = minkowski_mat(x, caract, p)\n",
      "    return cibles[np.argmin(dist)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u00c0 noter ici que `x` est le vecteur de caract\u00e9ristiques (sans \u00e9tiquette) de l'exemple de test. Ayant en mains la fonction `minkowski_mat`, les choses devrait \u00eatre simple, car dist va contenir un vecteur/liste des distances. En utilisant `numpy.argmin` on va trouver l'exemple/la fleur qui est la plus *proche* (dans le sens de minkowski) de `x` et ainsi, on va conclure que l'\u00e9tiquette (pr\u00e9dite) de `x` est celle de cet exemple."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous avons maintenant en notre possession toutes les composantes de l'algorithme 1-PPV. Il reste simplement \u00e0 en faire l'assemblage et \u00e0 tester le tout. \n",
      "\n",
      ">Rappelez vous que les fonctions d\u00e9finies dans les cellules de code pr\u00e9c\u00e9dentes sont accessibles dans toutes les cellules subs\u00e9quentes une fois les pr\u00e9c\u00e9dentes ex\u00e9cut\u00e9s.\n",
      "\n",
      "Afin de tester votre impl\u00e9mentation, \u00e9crivez une boucle `for` qui appelle, pour chaque exemple `i`, la fonction `ppv(iris[i,:-1],iris,p)` et qui compare la classe pr\u00e9dite avec `iris[i,-1]` (la vrai \u00e9tiquette). Les deux devraient toujours \u00eatre les m\u00eames (pourquoi?)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "iris = np.loadtxt('iris.txt')\n",
      "\n",
      "predictions = np.zeros(iris.shape[0])\n",
      "for i in range(iris.shape[0]):\n",
      "    predictions[i] = ppv(iris[i,:-1],iris)\n",
      "    \n",
      "cibles = iris[:,-1]\n",
      "print \"taux d'erreur:\",(1.0-(predictions==cibles).mean())*100.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "taux d'erreur: 0.0\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bonus / trucs auxquels r\u00e9fl\u00e9chir pour la prochaine fois"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Divisez l'ensemble iris en deux - un ensemble d'entra\u00eenement qui contient 100 exemples (un sous-ensemble al\u00e9atoire!) et un ensemble de test qui contient le reste.\n",
      "  * Utilisez le premier sous-ensemble comme donn\u00e9es sur lesquelles on va calculer les distances minkowski (donc donn\u00e9es d'entra\u00eenement).\n",
      "  * Calculez la performance de votre algorithme sur les deux ensembles. Pourquoi y a-t-il une telle diff\u00e9rence?               \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes = np.arange(iris.shape[0])\n",
      "# on utilise un seed pour que la s\u00e9rie al\u00e9atoire soit toujours la m\u00eame\n",
      "# cela rend les exp\u00e9riences reproductibles\n",
      "np.random.seed(3395)\n",
      "np.random.shuffle(indexes)\n",
      "\n",
      "train_set = iris[indexes[:50]]\n",
      "test_set = iris[indexes[50:]]\n",
      "\n",
      "# pr\u00e9diction sur l'ensemble d'entrainement en utilisant le m\u00eame ensemble pour trouver les 1-ppv\n",
      "train_predictions = np.zeros(train_set.shape[0])\n",
      "for i in range(train_set.shape[0]):\n",
      "    train_predictions[i] = ppv(train_set[i,:-1],train_set)\n",
      "    \n",
      "# pr\u00e9diction sur l'ensemble de test en utilisant l'ensemble d'entrainement pour trouver les 1-ppv\n",
      "test_predictions = np.zeros(test_set.shape[0])\n",
      "for i in range(test_set.shape[0]):\n",
      "    test_predictions[i] = ppv(test_set[i,:-1],train)\n",
      "    \n",
      "print \"Taux d'erreur sur l'ensemble d'entrainement\", (1.0-(train_predictions==train_set[:,-1]).mean())*100.0\n",
      "print \"Taux d'erreur sur l'ensemble de test\", (1.0-(test_predictions==test_set[:,-1]).mean())*100.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Taux d'erreur sur l'ensemble d'entrainement 0.0\n",
        "Taux d'erreur sur l'ensemble de test 5.0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Impl\u00e9mentez l'algorithme $k$-PPV avec $k > 1$\n",
      "   * Trouvez le $k$ qui donne la meilleure performance sur les deux ensembles - expliquez la diff\u00e9rence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "def kppv(x,data,k,n_classes,p=2): \n",
      "    les_comptes = np.zeros(n_classes)\n",
      "    \n",
      "    distances = minkowski_mat(x,data[:,:-1])\n",
      "    # on prend les indices jusqu'\u00e0 k du vecteurs de distance tri\u00e9\n",
      "    ind_voisins = np.argsort(distances)[:k]\n",
      "    cl_voisins = list(data[ind_voisins,-1]-1) # -1 car les cibles sont de 1 \u00e0 3 et on veut acc\u00e8der aux index 0 \u00e0 2 de les_comptes\n",
      "    \n",
      "    for j in range(min(k,data.shape[0])): # on prend le min de k et data.shape[0] pour permettre un k plus grand que le nombre d'exemples (m\u00eame si \u00e7a n'a pas de sens)\n",
      "        les_comptes[cl_voisins[j]] += 1\n",
      "    return np.argmax(les_comptes)\n",
      "\n",
      "# on va tester les k-ppv de 0 \u00e0 K\n",
      "K = 50\n",
      "n_classes = 3\n",
      "ks = xrange(1,K+1)\n",
      "results = np.zeros(len(ks))\n",
      "for i, k in enumerate(ks):\n",
      "    test_predictions = np.zeros(test_set.shape[0])\n",
      "    for j in range(test_set.shape[0]):\n",
      "        test_predictions[j] = kppv(test_set[j,:-1],train_set,k,n_classes)\n",
      "        \n",
      "    results[i] = (1.0-(test_predictions==test_set[:,-1]).mean())*100.0\n",
      "    \n",
      "print \"Meilleur r\u00e9sultat avec k =\",ks[np.argmax(results)]\n",
      "print \"Taux d'erreur sur l'ensemble de test\", np.max(results)\n",
      "\n",
      "# graphique du % d'erreur en fonction de k\n",
      "x = np.linspace(1, K,K)\n",
      "line, = plt.plot(x, results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "Meilleur r\u00e9sultat avec k ="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Taux d'erreur sur l'ensemble de test 98.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD9CAYAAAC2l2x5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x3caffd0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Que se passe-t-il lorsque $k=100$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u00e0 vous de le d\u00e9couvrir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}